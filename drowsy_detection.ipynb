{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöó Drowsy Driver Detection System\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Informasi Proyek\n",
    "\n",
    "**Judul**: Drowsy Driver Detection System menggunakan Vision Transformer (ViT)\n",
    "\n",
    "**Deskripsi**: Sistem deteksi kantuk pengemudi secara real-time menggunakan Computer Vision dan Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Topik Computer Vision yang Tercakup\n",
    "\n",
    "1. **Object Detection** - Deteksi wajah menggunakan Haar Cascade\n",
    "2. **Object Tracking** - Tracking wajah frame-by-frame\n",
    "3. **Object Recognition** - Klasifikasi drowsy/not drowsy\n",
    "4. **CNN (Vision Transformer)** - State-of-the-art deep learning architecture\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Informasi Model\n",
    "\n",
    "- **Architecture**: Vision Transformer (ViT-Base)\n",
    "- **Parameters**: 86M parameters\n",
    "- **Accuracy**: 97.52% \n",
    "- **Dataset**: UTA-RLDD (Real-Life Drowsiness Dataset)\n",
    "- **Classes**: \n",
    "  - 0: Not Drowsy\n",
    "  - 1: Drowsy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Import Libraries\n",
    "\n",
    "Import semua library yang dibutuhkan untuk project ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer Vision\n",
    "import cv2  # OpenCV untuk video processing\n",
    "from PIL import Image  # PIL untuk image manipulation\n",
    "\n",
    "# Deep Learning\n",
    "import torch  # PyTorch framework\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor  # Hugging Face Transformers\n",
    "\n",
    "# Data processing\n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # Data analysis (untuk log)\n",
    "\n",
    "# Utilities\n",
    "import time  # Timing operations\n",
    "import os  # File operations\n",
    "import sys  # System operations\n",
    "from datetime import datetime  # Timestamp\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import seaborn as sns  # Statistical visualization\n",
    "\n",
    "# Alert system\n",
    "import pygame  # Sound playback\n",
    "\n",
    "# Jupyter-specific\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 2. Setup Configuration\n",
    "\n",
    "Konfigurasi path dan parameters untuk sistem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== PATHS ====================\n",
    "MODEL_PATH = \"./models\"  # Path ke folder model ViT\n",
    "ALERT_SOUND_PATH = \"./assets/alert.wav\"  # Path ke alert sound\n",
    "LOG_PATH = \"./data/drowsy_log.csv\"  # Path untuk save log\n",
    "OUTPUT_VIDEO_PATH = None  # Set path jika mau save video output\n",
    "\n",
    "# ==================== PARAMETERS ====================\n",
    "DROWSY_THRESHOLD = 15  # Alert jika drowsy 15 frames berturut-turut (~0.5 detik at 30 FPS)\n",
    "PREDICTION_INTERVAL = 3  # Predict setiap 3 frame (untuk performa)\n",
    "VIDEO_SOURCE = 0  # 0 untuk webcam, atau path video file\n",
    "\n",
    "# ==================== DEVICE ====================\n",
    "# Gunakan GPU jika tersedia, kalau tidak pakai CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üì± Device: {device}\")\n",
    "\n",
    "# ==================== VERIFICATION ====================\n",
    "# Cek apakah model folder exists\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"‚ùå Error: Model folder not found at {MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Model folder found at {MODEL_PATH}\")\n",
    "    # List files in model folder\n",
    "    model_files = os.listdir(MODEL_PATH)\n",
    "    print(f\"   Files: {model_files}\")\n",
    "\n",
    "# Create data folder if not exists\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "print(\"‚úÖ Configuration setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 3. Load Vision Transformer Model\n",
    "\n",
    "Load pre-trained ViT model untuk klasifikasi drowsiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ Loading Vision Transformer model...\\n\")\n",
    "\n",
    "try:\n",
    "    # Load image processor (untuk preprocessing)\n",
    "    processor = ViTImageProcessor.from_pretrained(MODEL_PATH)\n",
    "    print(\"‚úÖ ViT Processor loaded\")\n",
    "    \n",
    "    # Load model\n",
    "    model = ViTForImageClassification.from_pretrained(MODEL_PATH)\n",
    "    model.to(device)  # Pindah ke GPU/CPU\n",
    "    model.eval()  # Set ke evaluation mode (tidak training)\n",
    "    print(\"‚úÖ ViT Model loaded\")\n",
    "    \n",
    "    # Print model info\n",
    "    print(\"\\nüìä Model Information:\")\n",
    "    print(f\"   Model type: {model.config.model_type}\")\n",
    "    print(f\"   Image size: {model.config.image_size}x{model.config.image_size}\")\n",
    "    print(f\"   Number of classes: {len(model.config.id2label)}\")\n",
    "    print(f\"   Classes: {model.config.id2label}\")\n",
    "    print(f\"   Hidden size: {model.config.hidden_size}\")\n",
    "    print(f\"   Num layers: {model.config.num_hidden_layers}\")\n",
    "    print(f\"   Num attention heads: {model.config.num_attention_heads}\")\n",
    "    \n",
    "    # Calculate total parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\n   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÅÔ∏è 4. Setup Face Detection\n",
    "\n",
    "Setup Haar Cascade classifier untuk deteksi wajah (Object Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üëÅÔ∏è Setting up Face Detection...\\n\")\n",
    "\n",
    "# Load Haar Cascade classifier untuk face detection\n",
    "# Haar Cascade adalah metode classical computer vision (bukan deep learning)\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    ")\n",
    "\n",
    "# Verifikasi cascade loaded\n",
    "if face_cascade.empty():\n",
    "    print(\"‚ùå Error: Haar Cascade not loaded!\")\n",
    "else:\n",
    "    print(\"‚úÖ Haar Cascade Face Detector loaded successfully!\")\n",
    "    print(\"   Method: Viola-Jones Algorithm (2001)\")\n",
    "    print(\"   Type: Classical Computer Vision (non-ML)\")\n",
    "\n",
    "def detect_face(frame):\n",
    "    \"\"\"\n",
    "    Deteksi wajah dari frame menggunakan Haar Cascade\n",
    "    \n",
    "    Args:\n",
    "        frame: Input frame (BGR format)\n",
    "        \n",
    "    Returns:\n",
    "        face_img: Cropped face image\n",
    "        coords: Tuple (x, y, w, h) koordinat face\n",
    "    \"\"\"\n",
    "    # Convert ke grayscale (Haar Cascade bekerja pada grayscale)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    # scaleFactor: parameter untuk image pyramid (1.3 = reduce 30% per level)\n",
    "    # minNeighbors: minimum neighbors untuk valid detection (higher = more strict)\n",
    "    # minSize: minimum face size in pixels\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(100, 100)\n",
    "    )\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        # Ambil face pertama (atau face terbesar jika ada multiple)\n",
    "        (x, y, w, h) = faces[0]\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        return face_img, (x, y, w, h)\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "print(\"\\n‚úÖ Face detection function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® 5. Image Preprocessing Function\n",
    "\n",
    "Fungsi untuk preprocess face image sebelum input ke model ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_face(face_img):\n",
    "    \"\"\"\n",
    "    Preprocess face image untuk ViT model\n",
    "    \n",
    "    Steps:\n",
    "    1. Convert BGR (OpenCV) ke RGB (PIL/Model)\n",
    "    2. Convert numpy array ke PIL Image\n",
    "    3. Resize ke 224x224 (ViT input size)\n",
    "    4. Normalize pixel values\n",
    "    5. Convert ke tensor\n",
    "    \n",
    "    Args:\n",
    "        face_img: Face image (BGR format dari OpenCV)\n",
    "        \n",
    "    Returns:\n",
    "        inputs: Preprocessed tensor siap untuk model\n",
    "    \"\"\"\n",
    "    # Convert BGR ke RGB\n",
    "    face_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert numpy array ke PIL Image\n",
    "    pil_image = Image.fromarray(face_rgb)\n",
    "    \n",
    "    # Preprocess menggunakan ViT processor\n",
    "    # Processor akan: resize, normalize, convert to tensor\n",
    "    inputs = processor(images=pil_image, return_tensors=\"pt\")\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "print(\"‚úÖ Preprocessing function defined!\")\n",
    "print(\"   Input: BGR image from OpenCV\")\n",
    "print(\"   Output: Preprocessed tensor (1, 3, 224, 224)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÆ 6. Prediction Function\n",
    "\n",
    "Fungsi untuk predict drowsiness dari face image (Object Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_drowsiness(face_img):\n",
    "    \"\"\"\n",
    "    Predict drowsiness dari face image menggunakan ViT model\n",
    "    \n",
    "    Args:\n",
    "        face_img: Face image (BGR format)\n",
    "        \n",
    "    Returns:\n",
    "        label: 'drowsy' atau 'notdrowsy'\n",
    "        confidence: Confidence score (0-1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Preprocess image\n",
    "        inputs = preprocess_face(face_img)\n",
    "        \n",
    "        # Move inputs ke device (GPU/CPU)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Inference (forward pass)\n",
    "        with torch.no_grad():  # Tidak perlu gradient (tidak training)\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits  # Raw scores dari model\n",
    "        \n",
    "        # Get predicted class (argmax)\n",
    "        predicted_class = logits.argmax(-1).item()\n",
    "        \n",
    "        # Calculate confidence scores menggunakan softmax\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)[0]\n",
    "        confidence = probabilities[predicted_class].item()\n",
    "        \n",
    "        # Get label dari id2label mapping\n",
    "        label = model.config.id2label[str(predicted_class)]\n",
    "        \n",
    "        return label, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Prediction error: {e}\")\n",
    "        return None, 0.0\n",
    "\n",
    "print(\"‚úÖ Prediction function defined!\")\n",
    "print(\"   Input: Face image (H, W, 3)\")\n",
    "print(\"   Output: Label (drowsy/notdrowsy) + Confidence (0-1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîä 7. Alert System\n",
    "\n",
    "Setup sistem alert (visual dan audio) ketika drowsiness terdeteksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pygame mixer untuk audio\n",
    "pygame.mixer.init()\n",
    "\n",
    "# Load alert sound jika file exists\n",
    "alert_sound = None\n",
    "if os.path.exists(ALERT_SOUND_PATH):\n",
    "    try:\n",
    "        alert_sound = pygame.mixer.Sound(ALERT_SOUND_PATH)\n",
    "        print(f\"‚úÖ Alert sound loaded from {ALERT_SOUND_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load alert sound: {e}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Alert sound not found at {ALERT_SOUND_PATH}\")\n",
    "    print(\"   Visual alert will still work\")\n",
    "\n",
    "def trigger_visual_alert(frame, text=\"‚ö†Ô∏è DROWSINESS DETECTED! ‚ö†Ô∏è\"):\n",
    "    \"\"\"\n",
    "    Tampilkan visual alert di frame\n",
    "    \n",
    "    Args:\n",
    "        frame: Video frame\n",
    "        text: Alert text\n",
    "        \n",
    "    Returns:\n",
    "        frame: Frame dengan alert overlay\n",
    "    \"\"\"\n",
    "    # Overlay merah semi-transparent di bagian atas\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (0, 0), (frame.shape[1], 100), (0, 0, 255), -1)\n",
    "    frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)\n",
    "    \n",
    "    # Text alert\n",
    "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]\n",
    "    text_x = (frame.shape[1] - text_size[0]) // 2\n",
    "    cv2.putText(frame, text, (text_x, 60),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def trigger_audio_alert():\n",
    "    \"\"\"Play alert sound jika tersedia\"\"\"\n",
    "    if alert_sound:\n",
    "        alert_sound.play()\n",
    "\n",
    "print(\"\\n‚úÖ Alert system setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 8. Visualization Function\n",
    "\n",
    "Fungsi untuk visualisasi informasi di frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_info(frame, face_coords, label, confidence, fps, stats):\n",
    "    \"\"\"\n",
    "    Gambar informasi lengkap di frame\n",
    "    \n",
    "    Args:\n",
    "        frame: Video frame\n",
    "        face_coords: Koordinat face (x, y, w, h)\n",
    "        label: Prediction label\n",
    "        confidence: Confidence score\n",
    "        fps: Frame per second\n",
    "        stats: Dictionary dengan statistik (total_frames, drowsy_count, etc)\n",
    "        \n",
    "    Returns:\n",
    "        frame: Frame dengan overlay informasi\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    # ========== FACE BOUNDING BOX ==========\n",
    "    if face_coords is not None:\n",
    "        (x, y, w, h) = face_coords\n",
    "        \n",
    "        # Warna: merah jika drowsy, hijau jika awake\n",
    "        color = (0, 0, 255) if label == \"drowsy\" else (0, 255, 0)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)\n",
    "        \n",
    "        # Label di atas bounding box\n",
    "        label_text = f\"{label.upper()}: {confidence:.1%}\"\n",
    "        cv2.putText(frame, label_text, (x, y-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "    \n",
    "    # ========== INFO PANEL (Kiri Atas) ==========\n",
    "    info_y = 30\n",
    "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, info_y),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    info_y += 30\n",
    "    cv2.putText(frame, f\"Frames: {stats['total_frames']}\", (10, info_y),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    info_y += 25\n",
    "    cv2.putText(frame, f\"Drowsy: {stats['drowsy_count']}\", (10, info_y),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    info_y += 25\n",
    "    cv2.putText(frame, f\"Alerts: {stats['alert_count']}\", (10, info_y),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    # ========== STATUS (Kanan Atas) ==========\n",
    "    status_text = \"STATUS: DROWSY!\" if label == \"drowsy\" else \"STATUS: AWAKE\"\n",
    "    status_color = (0, 0, 255) if label == \"drowsy\" else (0, 255, 0)\n",
    "    text_size = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
    "    status_x = width - text_size[0] - 10\n",
    "    cv2.putText(frame, status_text, (status_x, 30),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)\n",
    "    \n",
    "    # ========== DROWSINESS METER ==========\n",
    "    if label == \"drowsy\":\n",
    "        bar_width = 200\n",
    "        bar_height = 20\n",
    "        bar_x = width - bar_width - 10\n",
    "        bar_y = 50\n",
    "        \n",
    "        # Background\n",
    "        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height),\n",
    "                     (100, 100, 100), -1)\n",
    "        \n",
    "        # Progress\n",
    "        progress = min(stats['drowsy_counter'] / DROWSY_THRESHOLD, 1.0)\n",
    "        progress_width = int(bar_width * progress)\n",
    "        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + progress_width, bar_y + bar_height),\n",
    "                     (0, 0, 255), -1)\n",
    "        \n",
    "        # Text\n",
    "        cv2.putText(frame, f\"Alert in: {max(0, DROWSY_THRESHOLD - stats['drowsy_counter'])}\", \n",
    "                   (bar_x, bar_y - 5),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "print(\"‚úÖ Visualization function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé• 9. Main Detection Loop\n",
    "\n",
    "Real-time drowsiness detection dari webcam/video\n",
    "\n",
    "**Controls:**\n",
    "- Press **'q'** to quit\n",
    "- Press **'r'** to reset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STARTING DROWSY DRIVER DETECTION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nPress 'q' to quit, 'r' to reset statistics\\n\")\n",
    "\n",
    "# ==================== INITIALIZATION ====================\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Cannot open camera/video!\")\n",
    "else:\n",
    "    print(\"‚úÖ Video capture started!\")\n",
    "    \n",
    "    # Video writer setup (jika mau save output)\n",
    "    video_writer = None\n",
    "    if OUTPUT_VIDEO_PATH:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        fps_out = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width_out = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height_out = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        video_writer = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps_out, (width_out, height_out))\n",
    "        print(f\"üìπ Saving output to: {OUTPUT_VIDEO_PATH}\")\n",
    "    \n",
    "    # Log file setup\n",
    "    log_file = open(LOG_PATH, \"w\")\n",
    "    log_file.write(\"timestamp,frame,label,confidence,drowsy_counter,alert\\n\")\n",
    "    print(f\"üìù Saving log to: {LOG_PATH}\")\n",
    "    \n",
    "    # Statistics\n",
    "    stats = {\n",
    "        'total_frames': 0,\n",
    "        'drowsy_count': 0,\n",
    "        'alert_count': 0,\n",
    "        'drowsy_counter': 0\n",
    "    }\n",
    "    \n",
    "    # FPS calculation\n",
    "    fps_start_time = time.time()\n",
    "    fps_frame_count = 0\n",
    "    fps = 0\n",
    "    \n",
    "    # Prediction caching\n",
    "    frame_count = 0\n",
    "    last_prediction = None\n",
    "    last_confidence = 0.0\n",
    "    \n",
    "    print(\"\\n‚ñ∂Ô∏è  Detection started!\\n\")\n",
    "    \n",
    "    # ==================== MAIN LOOP ====================\n",
    "    try:\n",
    "        while True:\n",
    "            # Capture frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ö†Ô∏è End of video or cannot read frame\")\n",
    "                break\n",
    "            \n",
    "            stats['total_frames'] += 1\n",
    "            frame_count += 1\n",
    "            fps_frame_count += 1\n",
    "            \n",
    "            # Calculate FPS\n",
    "            if time.time() - fps_start_time >= 1.0:\n",
    "                fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "                fps_start_time = time.time()\n",
    "                fps_frame_count = 0\n",
    "            \n",
    "            # ========== FACE DETECTION ==========\n",
    "            face_img, face_coords = detect_face(frame)\n",
    "            \n",
    "            if face_img is not None:\n",
    "                # ========== DROWSINESS PREDICTION ==========\n",
    "                # Predict setiap PREDICTION_INTERVAL frames (untuk performa)\n",
    "                if frame_count % PREDICTION_INTERVAL == 0:\n",
    "                    label, confidence = predict_drowsiness(face_img)\n",
    "                    if label is not None:\n",
    "                        last_prediction = label\n",
    "                        last_confidence = confidence\n",
    "                else:\n",
    "                    # Gunakan prediksi terakhir\n",
    "                    label = last_prediction\n",
    "                    confidence = last_confidence\n",
    "                \n",
    "                # ========== ALERT LOGIC ==========\n",
    "                if label == \"drowsy\":\n",
    "                    stats['drowsy_counter'] += 1\n",
    "                    stats['drowsy_count'] += 1\n",
    "                    \n",
    "                    # Trigger alert jika melewati threshold\n",
    "                    if stats['drowsy_counter'] >= DROWSY_THRESHOLD:\n",
    "                        # Visual alert\n",
    "                        frame = trigger_visual_alert(frame)\n",
    "                        \n",
    "                        # Audio alert\n",
    "                        trigger_audio_alert()\n",
    "                        \n",
    "                        # Log alert\n",
    "                        if stats['drowsy_counter'] == DROWSY_THRESHOLD:\n",
    "                            stats['alert_count'] += 1\n",
    "                            print(f\"üö® ALERT #{stats['alert_count']} at frame {stats['total_frames']}\")\n",
    "                else:\n",
    "                    # Reset counter jika awake\n",
    "                    stats['drowsy_counter'] = 0\n",
    "                \n",
    "                # ========== VISUALIZATION ==========\n",
    "                frame = draw_info(frame, face_coords, label, confidence, fps, stats)\n",
    "                \n",
    "                # ========== LOGGING ==========\n",
    "                alert_status = \"YES\" if stats['drowsy_counter'] >= DROWSY_THRESHOLD else \"NO\"\n",
    "                log_file.write(f\"{time.time()},{stats['total_frames']},{label},{confidence:.4f},{stats['drowsy_counter']},{alert_status}\\n\")\n",
    "            \n",
    "            else:\n",
    "                # No face detected\n",
    "                cv2.putText(frame, \"No face detected\", (50, 50),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                stats['drowsy_counter'] = 0\n",
    "            \n",
    "            # ========== OUTPUT ==========\n",
    "            if video_writer:\n",
    "                video_writer.write(frame)\n",
    "            \n",
    "            # Show frame\n",
    "            cv2.imshow('Drowsy Driver Detection', frame)\n",
    "            \n",
    "            # ========== KEYBOARD CONTROLS ==========\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                print(\"\\n‚èπÔ∏è  Stopping detection...\")\n",
    "                break\n",
    "            elif key == ord('r'):\n",
    "                print(\"\\nüîÑ Resetting statistics...\")\n",
    "                stats = {\n",
    "                    'total_frames': 0,\n",
    "                    'drowsy_count': 0,\n",
    "                    'alert_count': 0,\n",
    "                    'drowsy_counter': 0\n",
    "                }\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚èπÔ∏è  Interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        # ==================== CLEANUP ====================\n",
    "        print(\"\\nüßπ Cleaning up...\")\n",
    "        cap.release()\n",
    "        if video_writer:\n",
    "            video_writer.release()\n",
    "        log_file.close()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # ==================== SUMMARY ====================\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"DETECTION SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Total Frames: {stats['total_frames']}\")\n",
    "        print(f\"Drowsy Detections: {stats['drowsy_count']}\")\n",
    "        print(f\"Alerts Triggered: {stats['alert_count']}\")\n",
    "        if stats['total_frames'] > 0:\n",
    "            drowsy_rate = (stats['drowsy_count'] / stats['total_frames']) * 100\n",
    "            print(f\"Drowsiness Rate: {drowsy_rate:.2f}%\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"‚úÖ Detection completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 10. Analyze Detection Log\n",
    "\n",
    "Analisis hasil deteksi dari log CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load log data\n",
    "if os.path.exists(LOG_PATH):\n",
    "    df = pd.read_csv(LOG_PATH)\n",
    "    \n",
    "    print(\"üìä Log Data Analysis\\n\")\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    print(f\"\\nAlert statistics:\")\n",
    "    print(df['alert'].value_counts())\n",
    "    \n",
    "    print(f\"\\nConfidence statistics:\")\n",
    "    print(df['confidence'].describe())\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nFirst 10 records:\")\n",
    "    display(df.head(10))\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Log file not found at {LOG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 11. Visualize Results\n",
    "\n",
    "Visualisasi hasil deteksi menggunakan matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(LOG_PATH) and len(df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Label distribution\n",
    "    df['label'].value_counts().plot(kind='bar', ax=axes[0, 0], color=['green', 'red'])\n",
    "    axes[0, 0].set_title('Detection Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Label')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # Plot 2: Confidence over time\n",
    "    axes[0, 1].plot(df['frame'], df['confidence'], alpha=0.7)\n",
    "    axes[0, 1].set_title('Confidence Score Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Frame')\n",
    "    axes[0, 1].set_ylabel('Confidence')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Drowsy counter over time\n",
    "    axes[1, 0].plot(df['frame'], df['drowsy_counter'], color='red', alpha=0.7)\n",
    "    axes[1, 0].axhline(y=DROWSY_THRESHOLD, color='orange', linestyle='--', label=f'Alert Threshold ({DROWSY_THRESHOLD})')\n",
    "    axes[1, 0].set_title('Drowsiness Counter Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Frame')\n",
    "    axes[1, 0].set_ylabel('Counter')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Alert distribution\n",
    "    df['alert'].value_counts().plot(kind='pie', ax=axes[1, 1], autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])\n",
    "    axes[1, 1].set_title('Alert Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/detection_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Visualization saved to data/detection_analysis.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì 12. Test with Single Image\n",
    "\n",
    "Test model dengan single image (untuk debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dengan capture frame dari webcam\n",
    "cap_test = cv2.VideoCapture(0)\n",
    "ret, test_frame = cap_test.read()\n",
    "cap_test.release()\n",
    "\n",
    "if ret:\n",
    "    # Detect face\n",
    "    face_img, face_coords = detect_face(test_frame)\n",
    "    \n",
    "    if face_img is not None:\n",
    "        # Predict\n",
    "        label, confidence = predict_drowsiness(face_img)\n",
    "        \n",
    "        # Draw result\n",
    "        (x, y, w, h) = face_coords\n",
    "        color = (0, 0, 255) if label == \"drowsy\" else (0, 255, 0)\n",
    "        cv2.rectangle(test_frame, (x, y), (x+w, y+h), color, 3)\n",
    "        cv2.putText(test_frame, f\"{label}: {confidence:.2%}\", (x, y-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        \n",
    "        # Display\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(cv2.cvtColor(test_frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Prediction: {label.upper()} ({confidence:.1%})\", fontsize=16)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Test completed!\")\n",
    "        print(f\"   Prediction: {label}\")\n",
    "        print(f\"   Confidence: {confidence:.2%}\")\n",
    "    else:\n",
    "        print(\"‚ùå No face detected in test image\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot capture test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù 13. Summary & Conclusion\n",
    "\n",
    "### üéØ Topik Computer Vision yang Diimplementasikan:\n",
    "\n",
    "1. **Object Detection** ‚úÖ\n",
    "   - Haar Cascade untuk face detection\n",
    "   - Classical computer vision approach (Viola-Jones)\n",
    "\n",
    "2. **Object Tracking** ‚úÖ\n",
    "   - Frame-by-frame face tracking\n",
    "   - Drowsiness counter tracking\n",
    "\n",
    "3. **Object Recognition** ‚úÖ\n",
    "   - Binary classification (drowsy/not drowsy)\n",
    "   - Vision Transformer (ViT) architecture\n",
    "   - 97.52% accuracy\n",
    "\n",
    "4. **CNN/Transformers** ‚úÖ\n",
    "   - ViT-Base (86M parameters)\n",
    "   - State-of-the-art deep learning\n",
    "   - Self-attention mechanism\n",
    "\n",
    "### üìä Performance:\n",
    "\n",
    "- **Model Accuracy**: 97.52%\n",
    "- **Real-time FPS**: 20-30 FPS (depending on hardware)\n",
    "- **Alert Response Time**: ~0.5 seconds (15 frames at 30 FPS)\n",
    "\n",
    "### üöÄ Future Improvements:\n",
    "\n",
    "1. Add Eye Aspect Ratio (EAR) calculation\n",
    "2. Implement head pose estimation\n",
    "3. Add yawn detection\n",
    "4. Multi-face support\n",
    "5. Cloud deployment\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: [Your Name]\n",
    "\n",
    "**Date**: December 2024\n",
    "\n",
    "**Course**: Computer Vision - Final Project\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
